# choose which model to use {tf : Transformer (BERT-like) / snrm : SNRM}
model: 'snrm'
vocab_size: 30522
batch_size: 64
lr: 0.0001
stopwords: "none"
remove_unk: False
patience: 5
samples_per_epoch_train: 5000
samples_per_epoch_val: 20000
log_every_ratio: 0.01
sparse_dimensions: 1000
large_out_biases: False
num_workers: 0
bottleneck_run: False
tf:
  hidden_size: 256
  num_of_layers: 2
  num_attention_heads: 4
  input_length_limit: 150
  # the method that the hidden states over all sequence steps are being aggregated {CLS, AVG, MAX}
  pooling_method: 'CLS'
  last_layer_norm: True
  act_func: "relu"
snrm:
  hidden_sizes: '200' # for multiple layers add '-' between hidden sizes  eg. ('100-400-200')
  n: 5
  dropout_p: 0.2
  n_gram_model: "cnn" # cnn or bert, defining the way that the n gram is being aggregated
  embedding_dim: 768
debug: False
max_rank: 1000
experiments_dir: "experiments_${dataset}"
temp_exp_prefix: "Dev..."
max_candidates_per_posting_list: -1
num_epochs: 100
num_of_workers_index: 7
l1_scalar: 0.0
num_of_decimals: 5
balance_scalar: 0.0
disable_cuda: False
seed: 1
data_path: "data/"
embedding: 'bert'
glove_embedding_path: '${data_path}/embeddings/glove.6B.300d.p'
glove_word2idx_path: '${data_path}/embeddings/glove.6B.300d_word2idx_dict.p'
# msmarco_query_val: '${data_path}/msmarco/msmarco-test2019-queries_43.${embedding}.tsv'
# msmarco_docs_val: '${data_path}/msmarco/msmarco-passagetest2019-top1000_43.${embedding}.tsv'
# msmarco_docs_train: '${data_path}/msmarco/collection.${embedding}.tsv'
# msmarco_query_train: '${data_path}/msmarco/queries.train.${embedding}.tsv'
msmarco_query_val: '${data_path}/retok_msmarco/msmarco-test2019-queries_43.tsv_${embedding}_stop_none_max_len_150.tsv'
msmarco_docs_val: '${data_path}/retok_msmarco/msmarco-passagetest2019-top1000_43.tsv_${embedding}_stop_none_max_len_150.tsv'
msmarco_query_train: '${data_path}/retok_msmarco/queries.train.tsv_${embedding}_stop_none_max_len_150.tsv'
msmarco_docs_train: '${data_path}/retok_msmarco/collection.tsv_${embedding}_stop_none_max_len_150.tsv'

msmarco_triplets_train: '${data_path}/msmarco/qidpidtriples.train.full.tsv'
msmarco_qrels_val: '${data_path}/msmarco/2019qrels-pass_filtered_ms_marco.txt'
robust_ranking_results_train: '${data_path}/robust04/robust04_AOL_anserini_top_1000_qld_no_stem_200k.filtered.txt'
robust_docs: '${data_path}/robust04/robust04_raw_docs.num_query_${embedding}_stop_${stopwords}_remove_unk_max_len_1500.tsv'
robust_query_train: '${data_path}/robust04/AOL-queries-all_filtered.txt.names_${embedding}_stop_${stopwords}_remove_unk_max_len_1500.tsv'
robust_ranking_results_test: '${data_path}/robust04/robust04_TREC_test_anserini_top_2000_qld_ranking_results'
robust_query_test: '${data_path}/robust04/04.testset_num_query_lower_${embedding}_stop_${stopwords}_remove_unk_max_len_1500.tsv'
robust_qrel_test: '${data_path}/robust04/qrels.robust2004.txt'
robust_ranking_results_strong: '${data_path}/robust04/qrels.robust2004.txt.strong_triples'
sampler: 'uniform'
target: 'binary'
top_k_per_query: -1
samples_per_query: -1
dataset: ''
trec_eval: 'trec_eval'
num_folds: 5
margin: 0
sample_j: False
single_sample: False